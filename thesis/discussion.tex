\chapter{Discussion of theoretical results}
\label{sec:discussion}

\section{Expected performance differences between evaluating with substitution versus environments}
\label{sec:expected-perf-diff}

\Cref{sec:evaluation-evalenv} discusses the empirical results of a few experiments on the performance of evaluation using the substitution method as originally described and implemented, and evaluation using environments as described in this paper. The result of that section show that the performance gain is highly dependent on the program, and it is not unexpected to see the performance of the substitution model of evaluation to outperform the same program evaluated using the environment model. Thus it is difficult to provide a general result about which model is preferred, strictly for performance reasons. Instead, we only provide the highly-parameterized results in the results of the two variations of the fibonacci program.

A way to remedy this is to collect information about expected or average programs, as described in \cref{sec:collect-edit-statistics}. The same is true to determine average performance characteristics of FAR, although this would be related to collecting editing behavior, not characteristics of the program itself.

A non-performance reason may tip the scale in favor of either using the substitution model or the evaluation model. As observed throughout this text, the substitution model is much simpler to formally state and implement, and may be sufficient in most use cases. However, environments allow for memoization. Environments also allow an implementation to be more amenable to lower-level implementations, because it does not require the runtime to keep a representation of the internal language (whereas substitution does). However, it is also important to keep in mind that environments in this implementation are closely tied to an immutable data structure (due to the frequency of copying and the efficiency of structural sharing), which may frustrate low-level implementations.

\section{Purity of implementation}
\label{sec:env-purity}
The purity of implementation is a recurring theme. While it should not affect the capability of the implementation, there is a strong urge to keep the implementation pure. Elegance, complexity, and runtime overhead is traded off for purity. The main decisions regarding purity are summarized here, and left for the consideration of future implementors.

One offender of performance is the use of the fixpoint form when evaluating recursive functions. This involves extra evaluation steps for unwrapping fixpoints, and can be avoided with self-referential data structures, and more easily implemented using \mintinline{text}|ref|s.

The evaluation process becomes stateful. Every call to \mintinline{text}|Evaluator.evaluate| takes an \mintinline{text}|EvalState.t| as both input and output. This maintains state but is still technically pure, much like a state monad. This state includes the environment identifier generator, the fill memoization context, and evaluation statistics such as evaluation steps. This complicates the formalization and the implementation, as we now have additional inputs and outputs to each evaluation judgment. This is also likely less performant than if some global state were used instead. This global state would have to be reset at the beginning of each evaluation or resumed evaluation.

\section{Summary of metatheorems}
\label{sec:metatheorem-summary}

\Crefrange{thm:eval-boundary-1}{thm:substitution-postprocessing} characterize the evaluation boundary and the results of substitution postprocessing. \Cref{thm:eval-correctness} states that the substitution-postprocessed result of evaluation with environments should match the result when evaluating using substitution. \Cref{thm:hole-numbering-postprocessing} describes the behavior of the hole closure numbering operation. \Crefrange{thm:filling-statics}{thm:commutativity} characterize the static and dynamic correctness of FAR. \Crefrange{thm:fill-reeval}{thm:resume-reeval} characterize closures in the outputs of the fill and resume steps of the FAR algorithm.

Most of these theorems describe the expected behavior of the result, such as the conditions on closures in the result. Thus we may think of these metatheorems as ``checksum theorems'' to informally check the correctness of the work. The correctness of these metatheorems is informally justified using by considering relevant inference rules.

Additionally, we may define ``adequacy theorems,'' which state that the result of the implemented algorithm matches the inference rules, and implement a series of checks in the code to test that this is indeed the case. However, Hazel does not have such a testing framework in place, and a more rigorous test framework is left for future work.

\section{FAR for notebook-style editing}
\label{sec:notebook-ui}

One of the primary qualities of computational notebooks is the ability to run sections of the code at a time, primarily for computational purposes. We may reproduce this behavior in a limited way.

We may model a notebook-style program as a linear sequence of sections or cells. Each cell, can be modeled as a set of variable bindings: the ``outputs'' of evaluating the section. We may interpret a \mintinline{text}|let| statement in Hazel to be a single-output section.

Consider the sample notebook-style program shown in \Cref{fig:matlab-notebook-example}. Here, we have two sections, which compute three different variables. If we add a third section containing the statement \mintinline{matlab}|a = x + y;|, then we may obtain the value of $a$ by only executing the third section and not re-evaluating the first two sections, because the workspace is saved.

Now, consider the comparable program in \Cref{fig:hazel-notebook-example}. If the user types in the expression \hmintinline{x + y} or \hmintinline{let a = x + y in /\heh1/}, then a fill operation is detected, and the new expression is computed with the environment stored in hole 1's closure. In fact, if the user continues to make any changes below the fourth \mintinline{text}|let| expression, they will all be considered to be valid fill operations against the edit state shown in \Cref{fig:hazel-notebook-example}, so the first four statements never have to be re-evaluated. As the user continues to edit downwards, new holes will be created and the newest edits may be considered fill operations from more recent edits.

Additionally, we have a reproducibility benefit here. In most notebook-style editors, such as MATLAB's live editor, running sections out of order may cause a different program output than if the program had been run in order. For example, if the user runs the section section twice after evaluating the first section \Cref{fig:matlab-notebook-example} is run twice in a row, then the output would be different than if the program was run from start to finish. On the other hand, the Hazel program in \Cref{fig:hazel-notebook-example} will always give the same result as if evaluation had begun from the top, as guaranteed by the commutativity property of FAR.

\begin{figure}
  \centering
  \begin{singlespace}
    \makebox[\textwidth][c]{
      \begin{subfigure}[b]{0.4\paperwidth}
        \inputminted[frame=single]{matlab}{lstings/matlab_notebook_example.m}
        \caption{Sample notebook-style program in MATLAB}
        \label{fig:matlab-notebook-example}
      \end{subfigure}
      \qquad
      \begin{subfigure}[b]{0.4\paperwidth}
        \inputhminted{hazel_notebook_example}
        \caption{Sample notebook-style program in Hazel}
        \label{fig:hazel-notebook-example}
      \end{subfigure}
    }
  \end{singlespace}
  \caption{Comparison of notebook-style programs in MATLAB and Hazel}
  \label{fig:notebook-comparison}
\end{figure}

The limitation of using Hazel as a computational notebook is that the fill-and-resume operation is limited to cases where there is a hole in a previous edit state as a parent of the root of the diff. If a user programs by always appending to or editing near the bottom of their program, FAR will be very beneficial because most edits will lead to valid fill operations. It may be difficult to quantify the real performance benefit due to large variations in programming styles. Different heuristics for choosing a past edit state to compare, as discussed in \cref{sec:far-past-edit-states}, will also affect the performance of FAR.

\section{Summary of generalized concepts}
\label{sec:summary-generalizations}

The work performed for FAR leads us to the following nice generalizations of some of the concepts we've encountered through this work.

\subsection{Generalized closures and the evaluation boundary}
\label{sec:generalized-closures}

Generalized closures form an integral part of this implementation. Previously, the term ``closure'' tends to refer to a function closure, but we find that allowing for a general container expression with a bound environment is extremely useful for our implementation. Not only do they tidy up the implementation by ``factoring out'' environments from the numerous expression forms that require them\footnote{This is true even in the case of evaluation with substitution, by separating environments from hole closures.}, but they characterize the evaluation boundary: expressions in the evaluated result that exist within a closure are ``paused'' evaluations that may be resumed later. Separating holes from closures also helps to facilitate fill-and-resume because we wish to substitute the hole with $\dfill$ without discarding the environment.

\subsection{A generalization of non-empty holes}
\label{sec:generalized-neholes}

Non-empty holes play a central hole in Hazel's ability to provide continuous feedback, as well as in the ability to resume computation in FAR. We may interpret an empty hole as encapsulating a well-formed expression in some incompatible outer expression.

It may be helpful to also imagine that the entire program lies in a non-empty hole. In this interpretation, regular program evaluation (from the start) may be considered a degenerate case of fill-and-resume, where the root of the diff is a non-fill diff that gets propagated up to this non-empty hole. This hole will also nicely serve as the parent for all holes in a non-complete program in the \mintinline{text}|HoleClosureInfo.t|, although the parent of this hole would then not be well-defined.

\subsection{FAR as a generalization of evaluation}
\label{sec:generalized-far}

It is possible to express every evaluation operation as a FAR operation, assuming that we have the ability to look back an unlimited number of edit states. The intuition behind this is that the initial state of a program is the empty hole $\hehole^1$. It is trivial to prove that using the rules given by the fill diff that every edit state produces either a no diff or a fill diff judgment against this edit state.

For practical reasons, it may be less efficient to perform a fill diff against an arbitrary number of states, or even to store the entire history of a program. Also, the whole history of a program may not be available. In the case of a parsed program or an example program, which is specified as an edit state rather than a history of edit actions, we would need additional machinery to produce a possible series of edit actions that leads to this state from the empty state.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
