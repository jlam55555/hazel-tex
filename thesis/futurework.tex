\chapter{Future work}
\label{sec:future_work}

\section{Simplification of the postprocessing algorithms}
\label{sec:postprocessing-simplification}

The postprocessing algorithms presented in \cref{sec:postprocessing-substitution,sec:hole-numbering-algorithm} are both memoized to avoid repeatedly postprocessing an environment multiple times. However, the latter algorithm (hole numbering) complicates memoization. This is due to the fact that holes need to be re-postprocessed each time it is encountered in a new parent in order to track the closure parents.

It would be desirable if we can avoid working around this, perhaps by reformulating the way hole parents are tracked. A possible solution is to implementing hole parent tracking as a separate postprocessing pass after hole closure numbering.

\section{Improvements to FAR}
\label{sec:far-improvements}

\subsection{Finishing the implementation of FAR}
\label{sec:finishing-far}

The implementation of FAR completed for this thesis is a limited proof-of-concept. The FAR detection mechanism (the structural diffing algorithm) and preprocessing steps are complete. However, due to limited time constraints, the implementation has not achieved parity with the theoretical exploration of FAR explored in this paper.

Firstly, a list of past edit states should be made accessible to the FAR detection algorithm. The current structure of the Hazel toplevel and the undo history makes this trickier because there may be multiple unrelated histories caused by switching programs (``cards'') in the top panel of the Hazel UI.

Secondly, the evaluation result from FAR should be memoized alongside the results from regular evaluation. The current implementation of normal evaluation is memoized and is not aware of the FAR operation.

Thirdly, the result of evaluating the program (\mintinline{text}|Result.t|) is not currently stored in the model, but the program's edit state (\mintinline{text}|Program.t|) is. This means that when the program result is needed in the Hazel UI, the program is re-evaluated. This is usually not a problem because of memoization, but FAR results are not memoized. It would be better to store the results of evaluation in the model and undo history to avoid this trouble.

Fourthly, is a slight issue with the current description of the \mintinline{text}|FillExp| variant $\hhole{d}_i$. This requires us to have access to the hole closure identifier $i$, which comes from the postprocessed result. However, we perform the FAR operation on the un-postprocessed result. To remedy this, we may begin evaluation from the post-processed result, which may cause us to change some of our assumptions about the evaluation boundary. Another solution would be to have an alternative postprocessing operation that renumbers holes but leaves alone the evaluation boundary.

\subsection{Memoization for environments during re-evaluation}
\label{sec:far-improv-memo-envs}

We introduced fill expressions $\hhole{d}_i$ in \cref{sec:far-preprocessing} in order to memoize the evaluation of filled expressions during re-evaluation.

It will also be beneficial to memoize the re-evaluation of closure environments. To illustrate why this is the case, consider the case of \Cref{fig:far-hole-closure-memoization}. In this example, the environment is evaluated twice, even though it is the same physical environment. Each environment will be re-evaluated each time it is encountered, leading to the same exponential blowup problem encountered when dealing with postprocessing in \Cref{fig:hole_renumbering_problem}. The implementation of this memoization is the same as before; we will need a new environment state variable mapping environment identifiers to evaluated environments.

\subsection{Choosing the edit state to fill from}
\label{sec:far-past-edit-states}

There are a number of possible design decisions when searching for a valid hole fill. Firstly, one must decide the maximum number of edit states to search: should it be a fixed number of edit states, or should it be given a fixed time budget? Is it best to cache edit states that recently led to a fill operation (\`a la LRU cache)? Is the most recent edit state that leads to a valid fill usually the best candidate, or even a good candidate? Would it be best to allow for user-configurable settings, or perhaps even for the user to manually select the previous edit from which to fill?

It will be useful to collect empirical data about user-editing behaviors, as discussed in \cref{sec:collect-edit-statistics}, in order to better tune these parameters. Alternatively, we may allow for some user configuration of FAR, as discussed in \cref{sec:far-improv-user-config}.

\subsection{User-configurable FAR}
\label{sec:far-improv-user-config}

The FAR procedure as described is a completely automatic process. However, the choice of which past edit state to choose may be tricky, as described in \cref{sec:far-past-edit-states}. It may be desirable for the user to manually set a past edit state as an ``anchor'' from which to set FAR, and thus override an automatic choice of past edit state. This reifies the concept of sections or section breaks from computational notebooks. However, since a user-chosen edit state may not lead to a valid fill diff, edit states that lead to an invalid fill diff will still have to be evaluated from scratch.

It may also be desirable to disable FAR completely, whether for debugging purposes or because it does not help performance much in the given circumstance. This should be a toggleable parameter in the sidebar.

Any changes to the interactiveness of the FAR operation will have a great effect on intuitiveness, ease-of-use, editing speed, and ostensible performance. These will all play a great effect on the usability and viscosity of editing a Hazel program.

\subsection{UI changes for notebook-style evaluation}
\label{sec:far-improv-notebook-ui}

We have motivated the use of Hazel with FAR for notebook-style evaluation in \cref{sec:notebook-ui}. It may be useful to the programmer to have additional visual aids to help enforce the benefits of resumed evaluation. This is currently a being developed on the \texttt{lab-notebook-ui} branch of the GitHub repository.

It may be useful to format the code editor using a series of sections. These sections will be syntactic sugar for sequences of let statements, and edits to the code in a section will only cause the current and subsequent sections to re-evaluate. This also presents a method to choose the edit state from which to fill that is intuitive to the user.

Another useful feature to evaluate FAR is to show evaluation statistics in the UI. The two evaluation statistics described in \cref{sec:step-counting} may be useful information to the user. These may inform the user what types of operations are more expensive when FAR is taken into account, and may actually promote a style of editing that maximizes the usage of FAR.

\section{Collection of editing statistics}
\label{sec:collect-edit-statistics}

The effects of switching evaluation to use environments instead of substitution, and the effect of different methods of choosing a previous edit state for FAR may drastically change the expected performance gain. We may only quantify expected differences in performance when concerned with specific types of programs or editing patterns. We also do not know the effect of manual or automatic FAR on editing viscosity.

Thus it will be useful to collect empirical statistics about user editing patterns, in order to gain a useful insight into the general expected effect on performance of this work. This information will likely help inform many other Hazel subprojects. Since Hazel is hosted online and is accessible to all, collecting usage statistics is technically very easy. Other online programming language environments, such as the Hedy incremental programming environment for programming education \cite{hermans2020hedy,gilsing2021gradual}, have collected user editing statistics to help direct their work.

\section{Generalization of memoized methods}
\label{sec:generalized-memoization}

Memoization plays an important part of this work. Memoization of environment plays a role in the substitution postprocessing (\cref{sec:postprocessing-substitution}), hole numbering postprocessing (\cref{sec:hole-numbering-algorithm}), structural equality checking (\cref{sec:fast-equals}), evaluation of filled expressions (\cref{sec:re-eval}), and re-evaluation of environments (\cref{sec:far-improv-memo-envs}). Despite this, each time memoization is used, the implementation and formalization are \textit{ad hoc}. This is due to the scattered discovery of performance problems and realization that memoization would be useful.

A future implementation of memoized algorithms will be well-served by a generalized characterization of memoization by environments. This should include a generalized notation, so that new memoized algorithms can be easily introduced. This should also include a precise characterization of what algorithms may be memoized; for example, the difficulty presented in \cref{sec:postprocessing-simplification} is due to the difficulty of memoizing the hole parent tracking process as part of the hole numbering process.

\section{Mechanization of metatheorems and rules}
\label{sec:formalization}

The metatheory of Hazelnut and Hazelnut Live were proved using the Agda proof assistant \cite{agda2017_git,agda2019_git}. A similar proof of the metatheory presented in this work is left to future work. Due to time constraints, we are satisfied with using the intuition presented as justifications for the metatheorems in this thesis.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
